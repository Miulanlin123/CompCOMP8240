{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U pip\n",
    "# pip install --index-url https://download.pytorch.org/whl/cu126 torch torchvision\n",
    "# pip install timm einops\n",
    "#pip install transformers accelerate\n",
    "# python linear_probe_cifar10_vit.py --model vit_base_patch16_224 --epochs 10 --batch_train 128\n",
    "#pip install huggingface_hub[hf_xet]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5d883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126 | CUDA build: 12.6\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4070 | count: 1\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, \"| CUDA build:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0), \"| count:\", torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1145ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pham Huy\\Desktop\\Data sciences in Macquarie\\10 COMP8240 Applied Data Sciences\\VisionVITs\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# file: sanity_vit.py\n",
    "import torch, timm\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d6f4875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "ok, logits shape: (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "model = timm.create_model(\"vit_base_patch16_224\", pretrained=True).to(device).eval()\n",
    "\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),\n",
    "])\n",
    "\n",
    "img = Image.open(urlopen(\"https://images.unsplash.com/photo-1518791841217-8f162f1e1131?w=512\")).convert(\"RGB\")\n",
    "x = tf(img).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = model(x)                   # [1, 1000] logits\n",
    "print(\"ok, logits shape:\", tuple(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd69dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=cuda | model=vit_b_16 | freeze_backbone=True\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to C:\\Users\\Pham Huy/.cache\\torch\\hub\\checkpoints\\vit_b_16-c867db91.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330M/330M [00:08<00:00, 40.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01 [782/782] loss=0.2750\n",
      "Epoch 01 | train_loss=0.2750 | test_acc=94.06%\n",
      "Ep 02 [782/782] loss=0.2141\n",
      "Epoch 02 | train_loss=0.2141 | test_acc=92.86%\n",
      "Ep 03 [782/782] loss=0.1924\n",
      "Epoch 03 | train_loss=0.1924 | test_acc=94.03%\n",
      "Ep 04 [782/782] loss=0.1770\n",
      "Epoch 04 | train_loss=0.1770 | test_acc=94.35%\n",
      "Ep 05 [782/782] loss=0.1639\n",
      "Epoch 05 | train_loss=0.1639 | test_acc=93.77%\n",
      "Ep 06 [782/782] loss=0.1541\n",
      "Epoch 06 | train_loss=0.1541 | test_acc=94.33%\n",
      "Ep 07 [782/782] loss=0.1543\n",
      "Epoch 07 | train_loss=0.1543 | test_acc=94.14%\n",
      "Ep 08 [782/782] loss=0.1480\n",
      "Epoch 08 | train_loss=0.1480 | test_acc=94.08%\n",
      "Ep 09 [782/782] loss=0.1454\n",
      "Epoch 09 | train_loss=0.1454 | test_acc=94.14%\n",
      "Ep 10 [782/782] loss=0.1427\n",
      "Epoch 10 | train_loss=0.1427 | test_acc=94.20%\n",
      "Done in 809.0s\n"
     ]
    }
   ],
   "source": [
    "# === ViT on CIFAR-10 with torchvision  ===\n",
    "# Works in a single notebook cell. Toggle FREEZE_BACKBONE for linear-probe vs finetune.\n",
    "\n",
    "import time, math, platform, torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# ----------------- config -----------------\n",
    "FREEZE_BACKBONE = True          # True = linear-probe (head only), False = full fine-tune\n",
    "MODEL_NAME = \"vit_b_16\"         # other options: vit_b_32 (faster), vit_l_16 (heavier)\n",
    "EPOCHS = 10\n",
    "BATCH  = 64                     # safe for 12GB with AMP\n",
    "TEST_B = 256\n",
    "LR     = 0.1 if FREEZE_BACKBONE else 5e-4\n",
    "MOM    = 0.9\n",
    "WD     = 0.0 if FREEZE_BACKBONE else 0.05\n",
    "SEED   = 42\n",
    "\n",
    "# ----------------- setup -----------------\n",
    "torch.manual_seed(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device={device} | model={MODEL_NAME} | freeze_backbone={FREEZE_BACKBONE}\")\n",
    "\n",
    "if hasattr(torch, \"set_float32_matmul_precision\"):\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# ----------------- data -----------------\n",
    "# torchvision ViT expects 224 + ImageNet stats\n",
    "mean,std=(0.485,0.456,0.406),(0.229,0.224,0.225)\n",
    "tf_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std),\n",
    "])\n",
    "tf_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std),\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(\"./data\", train=True,  download=True, transform=tf_train)\n",
    "test_ds  = datasets.CIFAR10(\"./data\", train=False, download=True, transform=tf_test)\n",
    "num_workers = 2 if platform.system()==\"Windows\" else 4\n",
    "pin = (device==\"cuda\")\n",
    "train_ld = DataLoader(train_ds, batch_size=BATCH, shuffle=True,\n",
    "                      num_workers=num_workers, pin_memory=pin, persistent_workers=True, prefetch_factor=2)\n",
    "test_ld  = DataLoader(test_ds,  batch_size=TEST_B, shuffle=False,\n",
    "                      num_workers=num_workers, pin_memory=pin, persistent_workers=True, prefetch_factor=2)\n",
    "\n",
    "# ----------------- model -----------------\n",
    "# Load ImageNet-pretrained weights\n",
    "weights = models.ViT_B_16_Weights.IMAGENET1K_V1 if MODEL_NAME==\"vit_b_16\" else None\n",
    "model = getattr(models, MODEL_NAME)(weights=weights).to(device)\n",
    "\n",
    "# Replace classifier head to 10 classes\n",
    "in_feats = model.heads.head.in_features           # torchvision ViT head\n",
    "model.heads.head = nn.Linear(in_feats, 10).to(device)\n",
    "\n",
    "# Freeze/unfreeze\n",
    "if FREEZE_BACKBONE:\n",
    "    for n,p in model.named_parameters():\n",
    "        if \"heads.head\" not in n:\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "# ----------------- optim/loss/amp -----------------\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "opt = optim.SGD(params, lr=LR, momentum=MOM, nesterov=True, weight_decay=WD) if FREEZE_BACKBONE \\\n",
    "      else optim.AdamW(params, lr=LR, weight_decay=WD)\n",
    "sched = None if FREEZE_BACKBONE else optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "use_amp = (device==\"cuda\")\n",
    "try:\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=use_amp)\n",
    "    def autocast(): return torch.amp.autocast(\"cuda\", enabled=use_amp)\n",
    "except TypeError:\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    def autocast(): return torch.cuda.amp.autocast(enabled=use_amp)\n",
    "\n",
    "# ----------------- eval -----------------\n",
    "@torch.inference_mode()\n",
    "def evaluate():\n",
    "    model.eval(); total=correct=0\n",
    "    with autocast():\n",
    "        for x,y in test_ld:\n",
    "            x,y = x.to(device,non_blocking=True), y.to(device,non_blocking=True)\n",
    "            pred = model(x).argmax(1)\n",
    "            total += y.size(0); correct += (pred==y).sum().item()\n",
    "    return 100.0*correct/total\n",
    "\n",
    "# ----------------- train -----------------\n",
    "t0=time.time(); num_batches=math.ceil(len(train_ds)/BATCH)\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train(); run=0.0\n",
    "    for i,(x,y) in enumerate(train_ld,1):\n",
    "        x,y = x.to(device,non_blocking=True), y.to(device,non_blocking=True)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with autocast():\n",
    "            loss = crit(model(x), y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt); scaler.update()\n",
    "        run += loss.item()\n",
    "        if i % 20 == 0 or i==num_batches:\n",
    "            print(f\"\\rEp {ep:02d} [{i}/{num_batches}] loss={run/i:.4f}\", end=\"\")\n",
    "    print()\n",
    "    if sched: sched.step()\n",
    "    acc = evaluate()\n",
    "    print(f\"Epoch {ep:02d} | train_loss={run/num_batches:.4f} | test_acc={acc:.2f}%\")\n",
    "print(f\"Done in {time.time()-t0:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd757c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to checkpoints/vit_b_16_cifar10_linearprobe.pt\n"
     ]
    }
   ],
   "source": [
    "import os, torch\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "ckpt_path = \"checkpoints/vit_b_16_cifar10_linearprobe.pt\"\n",
    "torch.save({\"state_dict\": model.state_dict(), \"arch\": \"vit_b_16\"}, ckpt_path)\n",
    "print(\"Saved to\", ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b433d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok, model loaded\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn, torch\n",
    "\n",
    "ckpt = torch.load(\"checkpoints/vit_b_16_cifar10_linearprobe.pt\", map_location=\"cpu\")\n",
    "m = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "m.heads.head = nn.Linear(m.heads.head.in_features, 10)\n",
    "m.load_state_dict(ckpt[\"state_dict\"], strict=True)\n",
    "m.eval()\n",
    "print(\"ok, model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1724425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 test accuracy: 94.20%\n"
     ]
    }
   ],
   "source": [
    "# If you still have `model`, `device`, and `test_ld` from the last run:\n",
    "acc = evaluate()\n",
    "print(f\"CIFAR-10 test accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e06f641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 test accuracy: 94.20%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total = correct = 0\n",
    "    for x, y in test_ld:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        pred = model(x).argmax(1)\n",
    "        total += y.size(0)\n",
    "        correct += (pred == y).sum().item()\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "acc = evaluate()\n",
    "print(f\"CIFAR-10 test accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from torchvision import models\n",
    "weights = models.ViT_B_32_Weights.IMAGENET1K_V1\n",
    "model = models.vit_b_32(weights=weights).to(device)\n",
    "model.heads.head = nn.Linear(model.heads.head.in_features, 10).to(device)\"\"\"\n",
    "\n",
    "# Swap to vit_b_32 (¼ tokens) or vit_tiny/small. Keep the rest the same:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
